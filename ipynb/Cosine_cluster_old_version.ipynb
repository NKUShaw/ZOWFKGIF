{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ff58df-c1d6-41dc-991b-2ba19ce24b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openke\n",
    "from openke.config import Trainer, Tester\n",
    "from openke.module.model import TransE\n",
    "from openke.module.loss import MarginLoss\n",
    "from openke.module.strategy import NegativeSampling\n",
    "from openke.data import TrainDataLoader, TestDataLoader, EmbeddingDataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7eed42-2686-4eab-bf0a-d5b8650967c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(model, data, head, tail):\n",
    "    batch_h = data['batch_h']\n",
    "    batch_t = data['batch_t']\n",
    "    combined_tensor = torch.cat((batch_h, batch_t))\n",
    "    unique_tensor = torch.unique(combined_tensor)\n",
    "\n",
    "    mask = (unique_tensor != head) & (unique_tensor != tail)\n",
    "    filtered_tensor = unique_tensor[mask]\n",
    "    if len(filtered_tensor) <= 1:\n",
    "        embedding = model.ent_embeddings(filtered_tensor[0]) - model.ent_embeddings(filtered_tensor[0])\n",
    "    else:\n",
    "        embed_1 = model.ent_embeddings(filtered_tensor[0])\n",
    "        embed_2 = model.ent_embeddings(filtered_tensor[1])\n",
    "        embedding = embed_1 - embed_2\n",
    "    \n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85dc98d4-a04a-40c3-917a-9d9bd80eb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "Cosine_dataloader = TrainDataLoader(\n",
    "    in_path=None,\n",
    "    tri_file='./benchmarks/YAGO3-10/train2id.txt',\n",
    "    ent_file=\"./benchmarks/YAGO3-10/entity2id.txt\",\n",
    "    rel_file=\"./benchmarks/YAGO3-10/relation2id.txt\",\n",
    "    nbatches=100,\n",
    "    threads=8,\n",
    "    sampling_mode=\"normal\",\n",
    "    bern_flag=1,\n",
    "    filter_flag=1,\n",
    "    neg_ent=25,\n",
    "    neg_rel=0)\n",
    "Cosine_model = TransE(\n",
    "\tent_tot = Cosine_dataloader.get_ent_tot(),\n",
    "\trel_tot = Cosine_dataloader.get_rel_tot(),\n",
    "\tdim = 200, \n",
    "\tp_norm = 1, \n",
    "\tnorm_flag = True)\n",
    "\n",
    "Cosine_model.to(device)\n",
    "Cosine_model.load_checkpoint('./checkpoint/YAGO/YAGO_TransE.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e856ea7-a587-4096-a1e8-1e2c2a4b1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_file = './benchmarks/YAGO3-10/train2id.txt'\n",
    "unlearn_file = './benchmarks/YAGO3-10/deleted_0.1.txt'\n",
    "schema_file = './benchmarks/YAGO3-10/type_constrain.txt'\n",
    "weight_file = './checkpoint/YAGO/YAGO_TransE.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215f004a-8bab-4801-9cb6-6ca97ad3417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhui/miniconda3/envs/xy_py38/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "Schema_dataloader = EmbeddingDataLoader.CosineSchemaDataLoader(\n",
    "    tri_file=tri_file,\n",
    "    unlearn_file=unlearn_file,\n",
    "    schema_file=schema_file,\n",
    "    weight_file=weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c341be-07b1-4b18-bc98-f0c852bd5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_triple = (67142,97190,9) #42784 51176 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9aab763-d77a-4546-8de3-2d69db4734d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2, e3, e4 = Schema_dataloader.query_match(Schema_dataloader.triples, Schema_dataloader.adj_matrix, query_triple, Schema_dataloader.labels\n",
    "                                              , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e86c2e0c-d607-44cd-8c3d-55dc112aa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(model, e1, e2):\n",
    "    e1 = torch.tensor(e1, dtype=torch.long).to(device)\n",
    "    e2 = torch.tensor(e2, dtype=torch.long).to(device)\n",
    "    embed_1 = model.ent_embeddings(e1)\n",
    "    embed_2 = model.ent_embeddings(e2)\n",
    "    embedding = embed_1 - embed_2\n",
    "    \n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af6c0a74-c6d1-490f-9d91-26853b8454b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cosine_Sampling = NegativeSampling(\n",
    "\tmodel = Cosine_model, \n",
    "\tloss = MarginLoss(margin = 5.0),\n",
    "\tbatch_size = Cosine_dataloader.get_batch_size()\n",
    ")\n",
    "\n",
    "trainer = Trainer(model = Cosine_Sampling, data_loader = Cosine_dataloader, train_times = 1000, alpha = 0.001, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89973651-0660-4576-8e21-8a2384286e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "total_loss = 0.0\n",
    "\n",
    "trainer.optimizer = torch.optim.Adam(\n",
    "    trainer.model.parameters(),\n",
    "    lr=trainer.alpha,\n",
    "    weight_decay=trainer.weight_decay,\n",
    ")\n",
    "\n",
    "with tqdm(total=len(Schema_dataloader.removed_triples), desc=\"Processing triples\") as pbar:\n",
    "    for idx, data in enumerate(Schema_dataloader.removed_triples):\n",
    "        e1, e2, e3, e4 = Schema_dataloader.query_match(Schema_dataloader.triples, Schema_dataloader.adj_matrix, data, Schema_dataloader.labels\n",
    "                                              , device)\n",
    "\n",
    "        Embed_Query = compute_embedding(Cosine_model, batch_subgraph, query_head, query_tail)\n",
    "        max_similarity = float('-inf')\n",
    "        all_iterations = 10\n",
    "        \n",
    "        trainer.optimizer.zero_grad()\n",
    "        \n",
    "        for _ in range(all_iterations):\n",
    "            mapping_head, mapping_tail, mapping_subgraph = Schema_dataloader.mapping_subgraph(query_subgraph=subgraph, adj_matrix=Schema_dataloader.adj_matrix, triples=Schema_dataloader.triples)\n",
    "            mapping_subgraph = Schema_dataloader.convert_to_batch_data(mapping_subgraph, device)\n",
    "            Embed_Map = compute_embedding(Cosine_model, mapping_subgraph, mapping_head, mapping_tail)\n",
    "            cosine_similarity = torch.nn.functional.cosine_similarity(Embed_Query, Embed_Map, dim=0)\n",
    "            average_cosine_similarity = cosine_similarity.max()\n",
    "            if average_cosine_similarity > max_similarity:\n",
    "                max_similarity = average_cosine_similarity\n",
    "        # print(Embed_Query)   \n",
    "        # loss_value = torch.tensor(1 - max_similarity)\n",
    "        loss_value = torch.log(1 - max_similarity + 1e-10)  \n",
    "        loss = loss_value.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        trainer.optimizer.step()\n",
    "        # print(Embed_Query)    \n",
    "        if idx == 1:\n",
    "            for name, param in Cosine_model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    print(f\"{name} has gradient with mean value {param.grad.mean().item()}\")\n",
    "                else:\n",
    "                    print(f\"{name} has no gradient\")\n",
    "        pbar.set_description(f\"Processing triples (Loss: {total_loss / (idx + 1):.4f})\")\n",
    "        pbar.update(1)\n",
    "\n",
    "print(f'Running Time: {time.time() - start_time}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454b9d42-85fd-4ce6-afb8-c42c8a11efa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing triples:   0%|                                                                    | 0/107904 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Files Path : ./benchmarks/YAGO3-10/train2id.txt\n",
      "Entity Files Path : ./benchmarks/YAGO3-10/entity2id.txt\n",
      "Relation Files Path : ./benchmarks/YAGO3-10/relation2id.txt\n",
      "The toolkit is importing datasets.\n",
      "The total of relations is 37.\n",
      "The total of entities is 123182.\n",
      "The total of train triples is 1079040.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing triples (Loss: -0.2499):   0%|                                          | 9/107904 [00:00<1:42:34, 17.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_const has no gradient\n",
      "pi_const has no gradient\n",
      "ent_embeddings.weight has gradient with mean value -3.870997150753029e-14\n",
      "rel_embeddings.weight has no gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing triples (Loss: nan): 100%|███████████████████████████████████████████| 107904/107904 [34:23<00:00, 52.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Time: 2064.08597779274s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "# total_loss = 0.0\n",
    "\n",
    "# trainer.optimizer = torch.optim.Adam(\n",
    "#     trainer.model.parameters(),\n",
    "#     lr=trainer.alpha,\n",
    "#     weight_decay=trainer.weight_decay,\n",
    "# )\n",
    "\n",
    "# with tqdm(total=len(Schema_dataloader.removed_triples), desc=\"Processing triples\") as pbar:\n",
    "#     for idx, data in enumerate(Schema_dataloader.removed_triples):\n",
    "#         query_head, query_tail = data[0], data[1]\n",
    "#         subgraph = Schema_dataloader.find_subgraph(Schema_dataloader.adj_matrix, data)\n",
    "#         batch_subgraph = Schema_dataloader.convert_to_batch_data(subgraph, device)\n",
    "#         Embed_Query = compute_embedding(Cosine_model, batch_subgraph, query_head, query_tail)\n",
    "#         max_similarity = float('-inf')\n",
    "#         all_iterations = 10\n",
    "        \n",
    "#         trainer.optimizer.zero_grad()\n",
    "        \n",
    "#         for _ in range(all_iterations):\n",
    "#             mapping_head, mapping_tail, mapping_subgraph = Schema_dataloader.mapping_subgraph(query_subgraph=subgraph, adj_matrix=Schema_dataloader.adj_matrix, triples=Schema_dataloader.triples)\n",
    "#             mapping_subgraph = Schema_dataloader.convert_to_batch_data(mapping_subgraph, device)\n",
    "#             Embed_Map = compute_embedding(Cosine_model, mapping_subgraph, mapping_head, mapping_tail)\n",
    "#             cosine_similarity = torch.nn.functional.cosine_similarity(Embed_Query, Embed_Map, dim=0)\n",
    "#             average_cosine_similarity = cosine_similarity.max()\n",
    "#             if average_cosine_similarity > max_similarity:\n",
    "#                 max_similarity = average_cosine_similarity\n",
    "#         # print(Embed_Query)   \n",
    "#         # loss_value = torch.tensor(1 - max_similarity)\n",
    "#         loss_value = torch.log(1 - max_similarity + 1e-10)  \n",
    "#         loss = loss_value.requires_grad_(True)\n",
    "#         loss.backward()\n",
    "#         total_loss += loss.item()\n",
    "#         trainer.optimizer.step()\n",
    "#         # print(Embed_Query)    \n",
    "#         if idx == 1:\n",
    "#             for name, param in Cosine_model.named_parameters():\n",
    "#                 if param.grad is not None:\n",
    "#                     print(f\"{name} has gradient with mean value {param.grad.mean().item()}\")\n",
    "#                 else:\n",
    "#                     print(f\"{name} has no gradient\")\n",
    "#         pbar.set_description(f\"Processing triples (Loss: {total_loss / (idx + 1):.4f})\")\n",
    "#         pbar.update(1)\n",
    "\n",
    "# print(f'Running Time: {time.time() - start_time}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f99560f-f839-4482-8793-f71601b25367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.5197, device='cuda:0', grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f793f4e-4e89-411c-aab8-caff150d5365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Files Path : ./benchmarks/YAGO3-10/\n",
      "The total of test triples is 5000.\n",
      "The total of valid triples is 5000.\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = TestDataLoader(\"./benchmarks/YAGO3-10/\", \"link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38502ac1-44cd-4058-917a-7b4fc19d36b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:50<00:00, 98.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012800000607967377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.007288469932973385,\n",
       " 39366.6171875,\n",
       " 0.012800000607967377,\n",
       " 0.00860000029206276,\n",
       " 0.003399999812245369)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no type constraint results:\n",
      "metric:\t\t\t MRR \t\t MR \t\t hit@10 \t hit@3  \t hit@1 \n",
      "l(raw):\t\t\t 0.005278 \t 56201.601562 \t 0.010800 \t 0.007000 \t 0.001800 \n",
      "r(raw):\t\t\t 0.006779 \t 24450.035156 \t 0.013200 \t 0.007600 \t 0.002400 \n",
      "averaged(raw):\t\t 0.006028 \t 40325.820312 \t 0.012000 \t 0.007300 \t 0.002100 \n",
      "\n",
      "l(filter):\t\t 0.006814 \t 54287.296875 \t 0.012000 \t 0.009000 \t 0.003200 \n",
      "r(filter):\t\t 0.007763 \t 24445.933594 \t 0.013600 \t 0.008200 \t 0.003600 \n",
      "averaged(filter):\t 0.007288 \t 39366.617188 \t 0.012800 \t 0.008600 \t 0.003400 \n",
      "0.012800\n"
     ]
    }
   ],
   "source": [
    "tester = Tester(model = Cosine_model, data_loader = test_dataloader, use_gpu = True)\n",
    "tester.run_link_prediction(type_constrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9238450-fab0-44d5-b29d-399e6752777c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py38",
   "language": "python",
   "name": "xy_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
