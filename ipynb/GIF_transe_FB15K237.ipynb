{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4438e9-50ce-4712-8818-c9295900cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openke\n",
    "import torch\n",
    "import torch.autograd\n",
    "import time\n",
    "import random\n",
    "from openke.config import Trainer, Tester\n",
    "from openke.module.model import TransE\n",
    "from openke.module.loss import MarginLoss\n",
    "from openke.module.strategy import NegativeSampling\n",
    "from openke.data import TrainDataLoader, TestDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97295b22-d930-416f-9ef0-ab41db00c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_triples(input_entity_file, input_triple_file, output_triple_file, remove_num=500):\n",
    "    with open(input_entity_file, 'r') as f:\n",
    "        total_entities = int(f.readline().strip())\n",
    "\n",
    "    selected_indices = set(random.sample(range(total_entities), remove_num))\n",
    "\n",
    "    with open(input_triple_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    header = lines[0]  \n",
    "    triples = lines[1:]  \n",
    "\n",
    "    filtered_triples = []\n",
    "    for triple in triples:\n",
    "        h, t, r = map(int, triple.split())\n",
    "        if h not in selected_indices and t not in selected_indices:\n",
    "            filtered_triples.append(triple)\n",
    "\n",
    "    with open(output_triple_file, 'w') as f:\n",
    "        f.write(str(len(filtered_triples)) + '\\n') \n",
    "        f.writelines(filtered_triples)  \n",
    "\n",
    "def filter_relations(input_relation_file, input_type_file, input_triple_file, output_triple_file, remove_num=5):\n",
    "    # 读取关系文件以获取关系的编号\n",
    "    with open(input_relation_file, 'r') as f:\n",
    "        f.readline()  # Skip the first line which contains the total number of relations\n",
    "        relations = [line.strip().split()[-1] for line in f]  # Assume relation ID is the last column\n",
    "\n",
    "    # 随机选择要删除的关系编号\n",
    "    selected_relations = set(random.sample(relations, remove_num))\n",
    "\n",
    "    # 读取类型文件并为每个选定的关系收集类型编号\n",
    "    relation_types = set()\n",
    "    with open(input_type_file, 'r') as f:\n",
    "        f.readline()  # Skip the first line with the total number of relations\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if parts[0] in selected_relations:  # Assume relation ID is the second column in this file\n",
    "                relation_types.update(parts[1:])  # Add all type IDs related to the relation\n",
    "\n",
    "    # 读取三元组文件，并过滤掉包含选定类型的三元组\n",
    "    with open(input_triple_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    header = lines[0]  # Header with the total count of triples, which we ignore\n",
    "    triples = lines[1:]  # Actual triples start from the second line\n",
    "\n",
    "    filtered_triples = []\n",
    "    for triple in triples:\n",
    "        _, t, _ = triple.split()  # Assume type ID is the second column in this file\n",
    "        if t not in relation_types:\n",
    "            filtered_triples.append(triple)\n",
    "\n",
    "    # 将过滤后的三元组写入输出文件\n",
    "    with open(output_triple_file, 'w') as f:\n",
    "        f.write(str(len(filtered_triples)) + '\\n')  # Write the count of remaining triples\n",
    "        f.writelines(filtered_triples)  # Write the triples\n",
    "        \n",
    "\n",
    "def calculate_gradients(model, data):\n",
    "    model.eval()  \n",
    "\n",
    "    loss = model.model({\n",
    "        'batch_h': torch.autograd.Variable(torch.from_numpy(data['batch_h']).cuda()),\n",
    "        'batch_t': torch.autograd.Variable(torch.from_numpy(data['batch_t']).cuda()),\n",
    "        'batch_r': torch.autograd.Variable(torch.from_numpy(data['batch_r']).cuda()),\n",
    "        'batch_y': torch.autograd.Variable(torch.from_numpy(data['batch_y']).cuda()),\n",
    "        'mode': data['mode']\n",
    "    })\n",
    "    loss_scalar = torch.mean(loss)\n",
    "    params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params_to_update = [param for name, param in model.named_parameters() if name.endswith('.weight')]\n",
    "    return torch.autograd.grad(loss_scalar, params_to_update, create_graph=True)\n",
    "\n",
    "def hvps(grad_all, model_params, h_estimate):\n",
    "    element_product = 0\n",
    "    for grad_elem, v_elem in zip(grad_all, h_estimate):\n",
    "        element_product += torch.sum(grad_elem * v_elem)\n",
    "    return_grads = torch.autograd.grad(element_product, model_params, create_graph=True)\n",
    "    \n",
    "    return return_grads\n",
    "    \n",
    "def GIF_unleanring(model, train_dataloader, test_dataloader, iteration=1, damp=0.0, scale=50):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for data in train_dataloader:\n",
    "        grad_full = calculate_gradients(model, data)\n",
    "\n",
    "    for data in test_dataloader:\n",
    "        grad_removed = calculate_gradients(model, data)\n",
    "\n",
    "    grad1 = [g1 - g2 for g1, g2 in zip(grad_full, grad_removed)]\n",
    "    grad2 = grad_removed\n",
    "    res_tuple = (grad_full, grad1, grad2)\n",
    "\n",
    "    v = tuple(grad1 - grad2 for grad1, grad2 in zip(res_tuple[1], res_tuple[2]))\n",
    "    h_estimate = tuple(grad1 - grad2 for grad1, grad2 in zip(res_tuple[1], res_tuple[2]))\n",
    "    \n",
    "    for _ in range(iteration):\n",
    "        model_params  = [p for p in model.parameters() if p.requires_grad]\n",
    "        hv = hvps(res_tuple[0], model_params, h_estimate)\n",
    "        with torch.no_grad():\n",
    "            h_estimate = [ v1 + (1-damp)*h_estimate1 - hv1/scale for v1, h_estimate1, hv1 in zip(v, h_estimate, hv)]\n",
    "            \n",
    "    params_change = [h_est / scale for h_est in h_estimate]\n",
    "    params_esti   = [p1 + p2 for p1, p2 in zip(params_change, model_params)]\n",
    "\n",
    "    print(time.time() - start_time)\n",
    "    \n",
    "    return params_esti\n",
    "\n",
    "def update_and_save_checkpoint(checkpoint_path, new_checkpoint_path, new_params):\n",
    "    weights = torch.load(checkpoint_path)\n",
    "    weights['ent_embeddings.weight'] = new_params[0]\n",
    "    weights['rel_embeddings.weight'] = new_params[1]\n",
    "    torch.save(weights, new_checkpoint_path)\n",
    "    print(f\"Updated checkpoint saved to {new_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "69fd059b-6b8b-419b-84b3-5379ebf9efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed_entities = 3000\n",
    "# removed_files = f'./benchmarks/FB15K237/removed_{removed_entities}_train2id.txt'\n",
    "# filter_triples('./benchmarks/FB15K237/entity2id.txt', './benchmarks/FB15K237/train2id.txt', removed_files, removed_entities)\n",
    "removed_relations = 9\n",
    "removed_files = f'./benchmarks/FB15K237/removed_{removed_relations}_train2id.txt'\n",
    "filter_relations(input_relation_file='./benchmarks/FB15K237/relation2id.txt', \n",
    "                 input_type_file='./benchmarks/FB15K237/type_constrain.txt',\n",
    "                 input_triple_file='./benchmarks/FB15K237/train2id.txt',\n",
    "                 output_triple_file = removed_files, remove_num=removed_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "81ac952e-a3c4-4832-9536-4d14546c4b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Files Path : ./benchmarks/FB15K237/removed_9_train2id.txt\n",
      "Entity Files Path : ./benchmarks/FB15K237/entity2id.txt\n",
      "Relation Files Path : ./benchmarks/FB15K237/relation2id.txt\n",
      "The toolkit is importing datasets.\n",
      "The total of relations is 237.\n",
      "The total of entities is 14541.\n"
     ]
    }
   ],
   "source": [
    "retrain_dataloader = TrainDataLoader(\n",
    "\tin_path = None, \n",
    "    tri_file = removed_files,\n",
    "    ent_file = \"./benchmarks/FB15K237/entity2id.txt\",\n",
    "    rel_file = \"./benchmarks/FB15K237/relation2id.txt\",\n",
    "\tnbatches = 100,\n",
    "\tthreads = 8, \n",
    "\tsampling_mode = \"normal\", \n",
    "\tbern_flag = 1, \n",
    "\tfilter_flag = 1, \n",
    "\tneg_ent = 25,\n",
    "\tneg_rel = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f3e9b8fc-0ddc-4939-8ec3-b6adb3eda90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total of train triples is 221600.\n",
      "Input Files Path : ./benchmarks/FB15K237/\n",
      "The total of test triples is 20466.\n",
      "The total of valid triples is 17535.\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = TestDataLoader(\"./benchmarks/FB15K237/\", \"link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "58c5fa4e-013a-48ef-a9f3-2a7204634fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_transe = TransE(\n",
    "\tent_tot = retrain_dataloader.get_ent_tot(),\n",
    "\trel_tot = retrain_dataloader.get_rel_tot(),\n",
    "\tdim = 200, \n",
    "\tp_norm = 1, \n",
    "\tnorm_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f455bb76-b29f-4aa1-bbca-eb0cd3bb960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_model = NegativeSampling(\n",
    "\tmodel = retrain_transe, \n",
    "\tloss = MarginLoss(margin = 5.0),\n",
    "\tbatch_size = retrain_dataloader.get_batch_size()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ba70197e-9496-47ae-8009-8f860374967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999 | loss: 1.770634: 100%|███████████████████████████████████████████████████| 1000/1000 [13:15<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "retrain_trainer = Trainer(model = retrain_model, data_loader = retrain_dataloader, train_times = 1000, alpha = 1.0, use_gpu = True)\n",
    "retrain_trainer.run()\n",
    "retrain_transe.save_checkpoint(f'./checkpoint/retrain_{removed_relations}_transe.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7fc2ea1a-cde6-44a6-8e7b-ef302d2393a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20466/20466 [00:17<00:00, 1200.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41864556074142456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24929894506931305,\n",
       " 477.66607666015625,\n",
       " 0.41864556074142456,\n",
       " 0.28249290585517883,\n",
       " 0.16212254762649536)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrain_transe.load_checkpoint(f'./checkpoint/retrain_{removed_relations}_transe.ckpt')\n",
    "retrain_tester = Tester(model = retrain_transe, data_loader = test_dataloader, use_gpu = True)\n",
    "retrain_tester.run_link_prediction(type_constrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "db0985b2-e920-46a5-8ef6-c3f7eea29225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no type constraint results:\n",
      "metric:\t\t\t MRR \t\t MR \t\t hit@10 \t hit@3  \t hit@1 \n",
      "l(raw):\t\t\t 0.077275 \t 733.083191 \t 0.186260 \t 0.072462 \t 0.025652 \n",
      "r(raw):\t\t\t 0.205607 \t 462.685638 \t 0.383807 \t 0.222125 \t 0.120004 \n",
      "averaged(raw):\t\t 0.141441 \t 597.884399 \t 0.285034 \t 0.147293 \t 0.072828 \n",
      "\n",
      "l(filter):\t\t 0.169097 \t 514.968506 \t 0.324098 \t 0.188557 \t 0.092886 \n",
      "r(filter):\t\t 0.329501 \t 440.363617 \t 0.513193 \t 0.376429 \t 0.231359 \n",
      "averaged(filter):\t 0.249299 \t 477.666077 \t 0.418646 \t 0.282493 \t 0.162123 \n",
      "0.418646\n",
      "Training Files Path : ./benchmarks/FB15K237/train2id.txt\n",
      "Entity Files Path : ./benchmarks/FB15K237/entity2id.txt\n",
      "Relation Files Path : ./benchmarks/FB15K237/relation2id.txt\n",
      "The toolkit is importing datasets.\n",
      "The total of relations is 237.\n",
      "The total of entities is 14541.\n",
      "----------------------------------------------------------------------\n",
      "The total of train triples is 272115.\n",
      "Training Files Path : ./benchmarks/FB15K237/removed_9_train2id.txt\n",
      "Entity Files Path : ./benchmarks/FB15K237/entity2id.txt\n",
      "Relation Files Path : ./benchmarks/FB15K237/relation2id.txt\n",
      "The toolkit is importing datasets.\n",
      "The total of relations is 237.\n",
      "The total of entities is 14541.\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = TrainDataLoader(\n",
    "\tin_path = None, \n",
    "    tri_file = \"./benchmarks/FB15K237/train2id.txt\",\n",
    "    ent_file = \"./benchmarks/FB15K237/entity2id.txt\",\n",
    "    rel_file = \"./benchmarks/FB15K237/relation2id.txt\",\n",
    "\tnbatches = 100,\n",
    "\tthreads = 8, \n",
    "\tsampling_mode = \"normal\", \n",
    "\tbern_flag = 1, \n",
    "\tfilter_flag = 1, \n",
    "\tneg_ent = 25,\n",
    "\tneg_rel = 0)\n",
    "print('----------------------------------------------------------------------')\n",
    "retrain_dataloader = TrainDataLoader(\n",
    "\tin_path = None, \n",
    "    tri_file = removed_files,\n",
    "    ent_file = \"./benchmarks/FB15K237/entity2id.txt\",\n",
    "    rel_file = \"./benchmarks/FB15K237/relation2id.txt\",\n",
    "\tnbatches = 100,\n",
    "\tthreads = 8, \n",
    "\tsampling_mode = \"normal\", \n",
    "\tbern_flag = 1, \n",
    "\tfilter_flag = 1, \n",
    "\tneg_ent = 25,\n",
    "\tneg_rel = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b05f028b-ecd0-4be9-a959-1914d3eb58d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total of train triples is 221600.\n"
     ]
    }
   ],
   "source": [
    "model = TransE(\n",
    "\tent_tot = train_dataloader.get_ent_tot(),\n",
    "\trel_tot = train_dataloader.get_rel_tot(),\n",
    "\tdim = 200, \n",
    "\tp_norm = 1, \n",
    "\tnorm_flag = True)\n",
    "model.to('cuda')\n",
    "model.load_checkpoint('./checkpoint/transe.ckpt')\n",
    "model = NegativeSampling(\n",
    "\tmodel = model, \n",
    "\tloss = MarginLoss(margin = 5.0),\n",
    "\tbatch_size = train_dataloader.get_batch_size()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c4a92b05-fc52-4993-8522-1a1bbbf525a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.467162609100342\n"
     ]
    }
   ],
   "source": [
    "params_esti = GIF_unleanring(model, train_dataloader, retrain_dataloader, iteration=100, damp=0.0, scale=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c1de7653-df1d-4873-b973-099dc724e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated checkpoint saved to ./checkpoint/GIF_9_TransE.ckpt\n"
     ]
    }
   ],
   "source": [
    "update_and_save_checkpoint(checkpoint_path='./checkpoint/transe.ckpt', \n",
    "                           new_checkpoint_path=f'./checkpoint/GIF_{removed_relations}_TransE.ckpt', \n",
    "                           new_params=params_esti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "eb42504b-6393-49e8-a31f-db6f70565ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Files Path : ./benchmarks/FB15K237/\n",
      "The total of test triples is 20466.\n",
      "The total of valid triples is 17535.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20466/20466 [00:16<00:00, 1244.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43968045711517334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2585415840148926,\n",
       " 255.31497192382812,\n",
       " 0.43968045711517334,\n",
       " 0.2900664508342743,\n",
       " 0.1673995852470398)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no type constraint results:\n",
      "metric:\t\t\t MRR \t\t MR \t\t hit@10 \t hit@3  \t hit@1 \n",
      "l(raw):\t\t\t 0.088247 \t 569.296326 \t 0.206049 \t 0.086680 \t 0.032200 \n",
      "r(raw):\t\t\t 0.247412 \t 167.087662 \t 0.436871 \t 0.269032 \t 0.155135 \n",
      "averaged(raw):\t\t 0.167830 \t 368.191986 \t 0.321460 \t 0.177856 \t 0.093668 \n",
      "\n",
      "l(filter):\t\t 0.171295 \t 363.839294 \t 0.329620 \t 0.191293 \t 0.093179 \n",
      "r(filter):\t\t 0.345789 \t 146.790634 \t 0.549741 \t 0.388840 \t 0.241620 \n",
      "averaged(filter):\t 0.258542 \t 255.314972 \t 0.439680 \t 0.290066 \t 0.167400 \n",
      "0.439680\n"
     ]
    }
   ],
   "source": [
    "# dataloader for test\n",
    "test_dataloader = TestDataLoader(\"./benchmarks/FB15K237/\", \"link\")\n",
    "\n",
    "# define the model\n",
    "unlearn_transe = TransE(\n",
    "\tent_tot = train_dataloader.get_ent_tot(),\n",
    "\trel_tot = train_dataloader.get_rel_tot(),\n",
    "\tdim = 200, \n",
    "\tp_norm = 1, \n",
    "\tnorm_flag = True)\n",
    "\n",
    "# test the model\n",
    "unlearn_transe.load_checkpoint(f'./checkpoint/GIF_{removed_entities}_TransE.ckpt')\n",
    "unlearn_tester = Tester(model = unlearn_transe, data_loader = test_dataloader, use_gpu = True)\n",
    "unlearn_tester.run_link_prediction(type_constrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f579c-db1a-4aca-8a97-437713a2fa2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py38",
   "language": "python",
   "name": "xy_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
